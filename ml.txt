Machine Learning
Purpose of machine learning is to discover recurring patterns in the data. ML tries to make predictions or decisions based on training data.
Sample datasets: https://archive.ics.uci.edu/ml/datasets.php

All learning algorithms require defining a set of features for each item which will be fed into the learning function. In many cases, defining the set of features is the most challenging part of using ML.

An important step is feature extraction and transformation.
Typical steps in a ML pipeline: Featurization -> Feature Vectors -> Training -> Model -> Model Evaluation -> Best Model.

Most learning algorithms have multiple params that can affect results, so real world pipelines will train muyltiple versions of a model and evaluate each one.

* Independent variable: Input into the model (for instance number of hours of study a student put into an exam)
* Dependent variable: The output or outcome resulting from altering these inputs (if the student passed the exam or not). For instance f(x) = 3*X+5=Y. X is the independent var. Y is the dependent var.

* Input variables may be called predictors, or independent variables.
* Outputs may be called responses, or dependent variables.
* Output may be quantitative (continuous) or qualitative (labels). Qualitative variables are also referred to as categorical or discrete or factors.

* A 3rd variable type is ordered cathegorical, such as small/med/large where there is an ordering between the values.

* Linear regression: modelling the relationship between a scalar response (dependent var) and one or more independent variables. If only one input var (indep var) => Simple linear regression. If multiple input vars => Multiple Linear Regression.
* Multivariate Linear Regression => multiple output variables are predicted based on the input(s).

ML can be split in:
	- Supervised Learning (develop predictive model based on both input and output data)
		- Classification (output is a choice between classes/labels: true/false. red/green/blue).
			- The output has discreete values in classification (qualitative, categoric, etc).
			- eg: Email classification: spam/non-spam, based on labeled examples of other items (emails known to be spam or not).
			
		- Regression (output is a number: stock prices, temperature, etc)
			The output is continuous in regression (quantitative).
			- eg: Product recomandation. It is known that person X prefers this list of products. We need to recommend him other products based on his past preferences.

	- Unsupervised Learning (discover an internal representation from input datra only)
		- Clustering: no output; find natural groups and patterns from input data only.
			e.g.: optimal placement of GSM antennas so that all customers receive good service.
	
	- Reinforcement Learning.
	
Method 1: Linear Regression. 
	Given a set of points int the n-th dimensional space, we try to aproximate them with a line. For new points the aproximation will be this line.
	
Method 2: k-NN: k-Nearest Neighbor
	- We find the k-nearest points in the input set (by a metric specified by us, like the Euclidian distance), and we average their responses.
	- If k=1, we always pick the closest point from the input data as the predictor. In this case, for each point coresponds a region in the space that is aproximated to it. This is a Voronoi Tesselation.

Method 3: Decision Trees.
	- If the target variable is discreete, the tree is called a classification tree. If the variable is continuous, the tree is called regression tree.
	

Method 4: Deep Learning (Artificial Neural Networks)
	- Artificial Neural Networks for Regression and Classification
	- Convolutional Neural Networks for Computer Vision
	- Recurrent Neural Networks for Time Series Analysis
	- Self Organizing Maps for Feature Extraction
	- Deep Boltzmann Machines for Recommendation Systems
	- Auto Encoders for Recommendation Systems
	
	- Inputs to ANNs: one ore more independent variables
	- Outputs can be:
		- a cathegogical varible (from a fixed set)
		= binary: yes/no
		- quantitative: like the price of an asset.
		
	- Weights are attached per each synapse (not neuron), and inside the next neuron they are summed, like this: Sum(i=1, m, Wi*Xi)
	- Activations functions
		- threshold function
		- Sigmoid function = f(x) = 1/(1+e^(-x))
		- Rectifier func = f(x) = max(0, x)
		- Hyperbolic tangent function = (1 - e ^ (-2x)) / (1 + e ^ (-2x)) - returns values between -1 and 1.
		= The value that a neuron passes to the next layer's neuron is the value of the activation function.
		- In most cases, the inner layers use the Rectifier activation function (i.e. just pass further the X value if positive), 
			and the final layer uses the sigmoid function.
	- ANNs with 1 layer are called Single Layer Feed-Forward ANNs. (or Perceptron).
	- ANNs Errors are calulated using a cost function. Most common => C = Sum((y-y0)^2 / 2). (Half of diff squared).
		Error is computed after one epoch, i.e. after the ANN is inputted with all data in the dataset. That is why the Cost function is a sum.
	- 1 epoch is when we go through all values in the training dataset and train our ANN.
	- After 1st epoch, we compute the Cost function, we adjust the weights, and then we feed again the dataset into our ANN with the updated weights. 
		We compute the Cost again, and the process repeats until we are satisfied with the error. This whole process is Back Propagation.
 	- When a neural network is not yet trained we have all the possible sinapses present between all neurons. Once it starts training, some of these synapses will have weight=0 (will dissapear)
	- Adjusting weights using brute force. Take every possible value for every weight and do a carthesian product. This would work, but it is extremely slow!
	- Gradient Descent & Stochastic Gradient Descent = solves the optimization problem where we try to optimize the cost function.
	- Gradient Descent is used when the Cost function is convex, i.e. it only has one global minimum. Stochastic GD is used when the cost function is not convex.
		- Also called Batch Gradient Descent, because we apply it per epoch, i.e. we do the backpropagation after we fed in all the rows in the dataset.
	- In stochastic gradient descent, we take the rows one by one and we adjust the weights after each row.
		- because in SGD we compute more cost functions, it has much larger fluctuations, so it can compute the global minimum, not just the local minimum.
		- it is a stochastic/random algorithm, compared to Batch Gradient Descent which is deterministic algorithm.
	- There is also an in-between method called Mini batch GD, that runs GD on a mini batch of the dataset and updates the roles afterwards.
	- ANN training:
		Step 1: Randomly initialize the weights to small numbers close to 0, but not 0.
		Step 2: Input the first observation of your dataset in the input layer, each feature in one input node.
		Step 3: Forward propagation: from left to right, the neurons are activated in a way that the impact of each neuron's activation is limited by the weights.
			Propagate the activations until getting the predicted result y.
		Step 4: Compare the predicted result to the actual result (expected result). Measure the generated error.
		Step 5: BackProp: from left to right, the error is back propagated. Update the weights according to how much they are responsible for the error. 
			The learning rate decides by how much we update the weights.
		Step 6: Repeat steps 1-5 and update weights after each observation - called Reinforcement Learning (SGD) or
				Repeat steps 1-5 and update the weights only after a batch of observations - called batch learning (GD).
		Step 7: After the whole training dataset is passed through the ANN that makes an epoch. Redo more epochs.
		
Questions:
	We have a training data set of 1000 items. Do we apply the backprop to adjust the weights after every item in the data set.
	
Refs:
	Efficient BackProp, Yann LeCun 1998, 
	Deep sparse rectifier neural networks, Xavier Glorot 2011.
	A list of cost functions used in NNs alongside applications, CrossValidated 2015 (link in stats.stackexchange)
	Sunway TaihuLight - world fastest super computer - operates at 93 PFLOPS = 93 * 10^15 floating points ops per second.
	A neural network in 13 lines of Python - part 2 gradient descent - Andrew Trask 2015.
	- Neural Networks and Deep Learning - Michael Nielson 2015 chap2 - online book - harder on the math side - backProp.
	@SuperDataScience
	Geffrey Hinton, father of Deep Learning.
	DNA storage.

Method SVM: Support Vector Machines
	- it is a classification method.
	- tries to find a "Maximum Margin Hyperplane" that has the maximum margin (distance) to the 2 sets of points in space.
	- these 2 distances (from the Maximum margin hyperplane and the closest point from each set) are called Support Vectors (they define the positive and negative hyperplanes).
	
Method 2: SVR: Support Vector Regression.

Method 5: Naive Bayes Classifier
	Bayes Theorem: P(A|B) = P(B|A) * P(A) / P(B). Probability of A given B is the probability of B given A times probability of A divided by the probability of B.
	* Problem 1: 2 machines produce wrenches. M1 produces 30 per hour, M2 produces 20 per hour. 1% of the produced wrenches are defective. The number of defective wrenches produced
	by M1 and M2 is equal. What is the probability that a wrench produced by M1/M2 is defective? P(Defective|M1) = P(M1|Defective) * P(Defective) / P(M1) => 50% * 1% / 40% = 1/80 or 1.25%.
	* Problem 2: What are the changes of having COVID after haveing a positive test with 99% success ratio. Percent of population with COVID is 120K/19M. Percent of positive tests is 6%.
		P(HaveCovid | PositiveTest) = P (PositiveTest | HaveCovid) * P(HaveCovid) / P(PositiveTest) = 99% * 120K/19M / 6%.
	
	- Posterior probability: is the probability an event will happen after all evidence or background information has been taken into account
	- Prior probability, in Bayesian statistical inference, is the probability of an event before new data is collected. This is the best rational assessment of the probability of an outcome based on the current knowledge before an experiment is performed.
	
		
